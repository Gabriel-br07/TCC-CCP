Metodologia
A metodologia aplicada neste projeto visa transformar documentos públicos do Sistema Eletrônico de Execução Unificada (SEEU) em uma base consultável por meio de técnicas de Processamento de Linguagem Natural (PLN), com foco em aprimorar o acesso e a interpretação de dados jurídicos utilizando Retrieval-Augmented Generation (RAG).

1. Coleta e organização dos dados
Inicialmente, serão identificados e reunidos os documentos públicos referentes ao SEEU, disponibilizados pelo Conselho Nacional de Justiça (CNJ), como resoluções, notas técnicas, relatórios e manuais. Estes documentos formarão a base textual do projeto. Após a coleta, os arquivos serão organizados em diretórios estruturados por tipo de conteúdo, data e origem, o que facilitará o processamento e indexação futuros (Silva & Andrade, 2023).

2. Pré-processamento dos dados
Os textos serão submetidos a um processo de limpeza e normalização, o que inclui a remoção de caracteres indesejados, correção de erros oriundos de OCR (caso os documentos estejam escaneados), e padronização textual. Em seguida, os documentos serão divididos em trechos menores, como parágrafos ou seções, para permitir uma vetorização mais eficiente e precisa (Cerri et al., 2021).

3. Vetorização do conteúdo
Os trechos segmentados serão vetorizados com o uso de modelos de embeddings como all-MiniLM-L6-v2, BAAI/bge-base, entre outros, capazes de transformar texto em vetores semânticos de alta qualidade. Isso permitirá buscas baseadas em similaridade de significado, indo além das palavras-chave exatas. Essa etapa é crucial para o funcionamento da pipeline RAG (Reimers & Gurevych, 2019).

4. Armazenamento vetorial
Os vetores gerados serão armazenados em um banco de dados vetorial, que funcionará como o repositório de conhecimento do sistema. Após análise das alternativas mais viáveis para o projeto, optou-se pelo uso do PostgreSQL com a extensão pgvector. Esta solução oferece robustez, é gratuita, de fácil manutenção e compatível com o ambiente de desenvolvimento acadêmico. Outras soluções como FAISS e Elasticsearch também foram avaliadas, mas não foram adotadas por motivos de integração e escalabilidade dentro do escopo deste trabalho (Johnson et al., 2019; Zeng et al., 2023).

5. Integração com LLM via RAG
A abordagem RAG será responsável por unir os dados vetorizados ao modelo de linguagem (LLM). O processo consiste em:

Vetorizar a pergunta do usuário;

Recuperar os vetores mais semelhantes no banco vetorial;

Injetar os textos correspondentes como contexto adicional ao modelo LLM;

Gerar a resposta contextualizada com base nas informações retornadas.

Essa estratégia evita que o modelo tenha que memorizar todo o conteúdo do SEEU, permitindo uma solução mais leve, transparente e atualizável. Além disso, essa arquitetura reduz significativamente o risco de alucinações por parte do modelo, aumentando a confiabilidade das respostas (Lewis et al., 2020).

6. Tecnologias utilizadas
As ferramentas e linguagens escolhidas foram pensadas para viabilizar a pesquisa com foco na reprodutibilidade, eficiência e custo zero:

Python – Linguagem principal para desenvolvimento da pipeline;

LangChain – Framework que facilita a implementação da lógica RAG;

Transformers (via HuggingFace) – Para uso de embeddings e modelos LLM;

PostgreSQL + pgvector – Banco de dados vetorial escolhido;

VS Code e GitHub – Para versionamento e colaboração do projeto.

Referências
Cerri, R., Lima, P., & Cozman, F. G. (2021). Processamento de Linguagem Natural com Python. Novatec Editora.

Johnson, J., Douze, M., & Jégou, H. (2019). Billion-scale similarity search with GPUs. Facebook AI Research.

Lewis, P., Oguz, B., Rinott, R., Riedel, S., & Stoyanov, V. (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. arXiv preprint arXiv:2005.11401.

Reimers, N., & Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. EMNLP 2019.

Silva, M. L., & Andrade, R. C. (2023). Inteligência Artificial no Judiciário: Análise da Implementação do SEEU. Revista Brasileira de Direito e Tecnologia.

Zeng, L., Wu, W., & Lin, J. (2023). Benchmarking Vector Search in Modern Databases. arXiv:2305.12588.

